{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import  pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16, DenseNet121, ResNet50, DenseNet201\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPool2D, BatchNormalization, Attention, Reshape, Multiply\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from dataclasses import dataclass, asdict\n",
    "import yaml\n",
    "from typing import Optional, Union, List\n",
    "from dacite import from_dict\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import itertools\n",
    "import ast\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Resize:\n",
    "    resizeW: int\n",
    "    resizeH: int\n",
    "\n",
    "@dataclass\n",
    "class DullRazor:\n",
    "    enabled: bool\n",
    "    razorblur: str\n",
    "    mediankernel_razorblur: int\n",
    "    filterstructure:int\n",
    "    lowerbound:int\n",
    "    inpaintmat:int\n",
    "\n",
    "@dataclass\n",
    "class Blur:\n",
    "    enabled: bool\n",
    "    normalblur: str\n",
    "    mediankernel_blur: int\n",
    "    blurnum: int\n",
    "\n",
    "@dataclass\n",
    "class Softattention:\n",
    "    alpha: float\n",
    "    beta: float\n",
    "    gamma: float\n",
    "    \n",
    "@dataclass\n",
    "class AttentionConfig:\n",
    "    resize: Resize\n",
    "    dull_razor: DullRazor\n",
    "    blur: Blur\n",
    "    soft_attention: Softattention\n",
    "        \n",
    "@dataclass\n",
    "class LossParams:\n",
    "    func: str\n",
    "    params: Optional[str]\n",
    "\n",
    "@dataclass\n",
    "class OptimizerParams:\n",
    "    func: str\n",
    "    params: Optional[str]\n",
    "\n",
    "@dataclass\n",
    "class InputDataParams:\n",
    "    input_size: str\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    batch_size: int\n",
    "    arch: str\n",
    "    freeze_pretrained: bool\n",
    "    steps_per_epoch: int\n",
    "    metrics: List[str]\n",
    "    pretrained_weight: Optional[str]\n",
    "    loss: Optional[LossParams]\n",
    "    optimizer: Optional[OptimizerParams]\n",
    "    class_weight_mu: float\n",
    "\n",
    "@dataclass\n",
    "class ModelsConfig:\n",
    "    model_name: str\n",
    "    input_params: InputDataParams\n",
    "    model_params: ModelParams\n",
    "    attention_config: Optional[AttentionConfig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_config = \"\"\"\n",
    "vgg16:\n",
    "  model_name: \"vgg16-1\"\n",
    "  input_params:\n",
    "    input_size: (224,224)\n",
    "  model_params:\n",
    "    batch_size: 32\n",
    "    arch: tf.keras.applications.DenseNet121\n",
    "    freeze_pretrained: True\n",
    "    steps_per_epoch: 100\n",
    "    metrics: ['accuracy']\n",
    "    loss:\n",
    "      func: \"sparse_categorical_crossentropy\"\n",
    "    optimizer:\n",
    "      func: \"Adam\"\n",
    "      params: \"{'learning_rate':1e-3}\"\n",
    "    class_weight_mu: 1\n",
    "  attention_config:\n",
    "    resize:\n",
    "      resizeW: 224\n",
    "      resizeH: 224\n",
    "    dull_razor:\n",
    "      enabled: True\n",
    "      razorblur: \"M\"\n",
    "      mediankernel_razorblur: 3\n",
    "      filterstructure: 5\n",
    "      lowerbound: 5\n",
    "      inpaintmat: 3\n",
    "    blur:\n",
    "      enabled: True\n",
    "      normalblur: \"M\"\n",
    "      mediankernel_blur: 5\n",
    "      blurnum: 5\n",
    "    soft_attention:\n",
    "      alpha: 0.7\n",
    "      beta: 0.3\n",
    "      gamma: 0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional Preprocessing\n",
    "class Ham10000Attention:\n",
    "    \n",
    "    def __init__(self, model, attention_config):\n",
    "        self.config = attention_config\n",
    "        \n",
    "        self.input_shape = (self.config.resize.resizeW, self.config.resize.resizeH)\n",
    "        self.model = model\n",
    "        #self.attention_output = self.heatmap(self.image, model)\n",
    "    \n",
    "    def resize(self, img):\n",
    "        return cv2.resize(img, self.input_shape, interpolation=cv2.INTER_LINEAR)    \n",
    "            \n",
    "    def dull_razor(self, img):\n",
    "        cfg = self.config.dull_razor\n",
    "        if cfg.razorblur == \"M\":\n",
    "            img = cv2.medianBlur(img,cfg.mediankernel_razorblur)\n",
    "        elif cfg.razorblur == \"G\":\n",
    "            img = cv2.GaussianBlur(img, (cfg.mediankernel_razorblur, cfg.mediankernel_razorblur),0)\n",
    "\n",
    "        #gyimage = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        #filtersize = (cfg.filterstructure,cfg.filterstructure)\n",
    "        #kernelrazor = cv2.getStructuringElement(cv2.MORPH_RECT, filtersize)\n",
    "        #gyimage = cv2.morphologyEx(gyimage, cv2.MORPH_BLACKHAT, kernelrazor)\n",
    "#\n",
    "        #retrazor, maskrazor = cv2.threshold(gyimage, cfg.lowerbound, 255, cv2.THRESH_BINARY)\n",
    "        #img = cv2.inpaint(img, maskrazor, cfg.inpaintmat, cv2.INPAINT_TELEA)\n",
    "        return img\n",
    "\n",
    "    def blur(self, img):\n",
    "        cfg = self.config.blur\n",
    "        if cfg.normalblur == \"M\":\n",
    "            img = cv2.medianBlur(img, cfg.mediankernel_blur)\n",
    "        elif cfg.normalblur == \"G\":\n",
    "            img = cv2.GaussianBlur(img, (cfg.mediankernel_blur, cfg.mediankernel_blur), 0)\n",
    "        return img\n",
    "\n",
    "    def softention_preprocess(self, img):\n",
    "        first = preprocess_input(img)\n",
    "        expanded_image = np.expand_dims(first, 0)\n",
    "        return expanded_image\n",
    "\n",
    "    def softention_mapping(self, img, LayerNumber, input_shape, SoftentionImage):\n",
    "        cfg = self.config.soft_attention\n",
    "        activated = self.model.predict(img)\n",
    "        output = np.abs(activated)\n",
    "        output = np.sum(output, axis = -1).squeeze() \n",
    "        output = cv2.resize(output, input_shape)\n",
    "        output /= output.max() \n",
    "        #output *= 255 \n",
    "        #Weights =  255 - output.astype('uint8')\n",
    "#\n",
    "        #heatmap = cv2.applyColorMap(Weights, cv2.COLORMAP_JET)\n",
    "        #heatmap = cv2.addWeighted(heatmap, cfg.alpha, SoftentionImage, cfg.beta, cfg.gamma)\n",
    "        return output\n",
    "    \n",
    "    def heatmap(self, img):\n",
    "        #resized_image = self.resize(img)\n",
    "        hair_removed_image = self.dull_razor(img)\n",
    "        softentionImage = self.blur(hair_removed_image)\n",
    "        expanded_image = self.softention_preprocess(softentionImage)\n",
    "        heatmap = self.softention_mapping(expanded_image, -1, self.input_shape, softentionImage)\n",
    "        return heatmap\n",
    "    \n",
    "    def preprocess(self, img):\n",
    "        \n",
    "        img = self.resize(img)\n",
    "        heatmap = self.heatmap(img)\n",
    "        mask = heatmap.reshape(self.config.resize.resizeW,self.config.resize.resizeH,1)\n",
    "        out = Multiply()([tf.cast(img, tf.float32),mask])\n",
    "        img = tf.keras.utils.normalize(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "\n",
    "  def __init__(self, train_dir, test_dir, model_name, model_dir, batch_size = 16, \n",
    "               target_size = (224,224), model_params = None, class_weight_mu = 0.4, attention_config = None,retrain = False):\n",
    "    self.train_dir = train_dir\n",
    "    self.test_dir = test_dir\n",
    "    self.batch_size = batch_size\n",
    "    self.target_size = target_size\n",
    "    self.model_name = model_name\n",
    "    self.model_dir = model_dir\n",
    "    self.checkpoint_path = f\"{self.model_dir}/{self.model_name}\"\n",
    "    if attention_config:\n",
    "        print(\"attention model\")\n",
    "        self.attention_model = self.attention(attention_config)\n",
    "    else:\n",
    "        self.attention_model = None\n",
    "    self.train_generator, self.validation_generator, self.attention_generator = self.get_generators()\n",
    "    self.set_class_weight(class_weight_mu)\n",
    "    self.model_params = model_params\n",
    "    if retrain == True or not(self.load_trained_model()):\n",
    "      if model_params:\n",
    "        self.register_model(self.model_architecture(model_params))\n",
    "\n",
    "  @staticmethod\n",
    "  def load_from_config(config, base_dir = '/home/ubuntu/data/3classes/', retrain = False):\n",
    "    train_dir = f\"{base_dir}/HAM10000_train_by_class/\"\n",
    "    test_dir = f\"{base_dir}/HAM10000_test_by_class/\"\n",
    "    model_dir = f\"{base_dir}/models\"\n",
    "    cfg = from_dict(data_class=ModelsConfig, data=config)\n",
    "    model_trainer = ModelTrainer(train_dir, test_dir, cfg.model_name, model_dir, batch_size = cfg.model_params.batch_size or 16,\n",
    "                                 target_size = eval(cfg.input_params.input_size),class_weight_mu = cfg.model_params.class_weight_mu,\n",
    "                                 model_params = cfg.model_params, attention_config = cfg.attention_config, retrain = retrain)    \n",
    "    return model_trainer\n",
    "\n",
    "  @classmethod\n",
    "  def img_normalize(cls,img):\n",
    "    #img = cv2.imread(img)\n",
    "    mean = [0.5456423, 0.5700427, 0.7630366]\n",
    "    sd = [0.15261365, 0.16997027, 0.14092803]\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = img.astype('float32')/255.\n",
    "    img = (img - mean) / sd\n",
    "    #img = cv2.normalize(img, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    return img     \n",
    "  \n",
    "  def attention(self, attention_config):\n",
    "    attention_pretrained_model = ResNet50(input_shape=(224,224, 3),\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "    out_layer = attention_pretrained_model.layers[-1]\n",
    "    model = tf.keras.models.Model(inputs = attention_pretrained_model.inputs, outputs = out_layer.output)\n",
    "    return Ham10000Attention(model,attention_config)\n",
    "  \n",
    "  def register_model(self, model):\n",
    "    self.model = model\n",
    "    self.model.compile(loss=self.model_params.loss.func, optimizer=self.optimizer(), metrics=self.model_params.metrics)\n",
    "    if not os.path.exists(self.checkpoint_path):\n",
    "      os.makedirs(self.checkpoint_path)\n",
    "    self.model.save(f\"{self.checkpoint_path}/model.h5\")\n",
    "\n",
    "  def optimizer(self):\n",
    "    optimizer_func = eval(self.model_params.optimizer.func)\n",
    "    optimizer_params = ast.literal_eval(self.model_params.optimizer.params)\n",
    "    optimizer = optimizer_func(**optimizer_params)\n",
    "    return optimizer\n",
    "\n",
    "  def summary(self):\n",
    "    self.model.summary()\n",
    "\n",
    "  def show_samples(self, rows = 4, columns = 4):\n",
    "    x, y = next(self.train_generator)\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for i in range(0, columns*rows):\n",
    "      img = x[i].astype(int)\n",
    "      fig.add_subplot(rows, columns, i+1)\n",
    "      plt.imshow(img)\n",
    "    plt.show()\n",
    "  \n",
    "  def get_generators(self):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "                                  featurewise_center=True, \n",
    "                                  featurewise_std_normalization=True\n",
    "                                  #rotation_range = 20,\n",
    "                                  #width_shift_range = 0.2,\n",
    "                                  #height_shift_range = 0.2,\n",
    "                                  #shear_range = 0.2,\n",
    "                                  #horizontal_flip = True,\n",
    "                                  #vertical_flip = True,\n",
    "                                  #preprocessing_function = ModelTrainer.img_normalize)\n",
    "                                  #preprocessing_function = self.attention_model.preprocess\n",
    "                                  #self.attention_model.preprocess)\n",
    "                                  #fill_mode = 'nearest'\n",
    "                                    )\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                                     featurewise_center=True, \n",
    "                                    featurewise_std_normalization=True\n",
    "                                    #preprocessing_function = self.attention_model.preprocess\n",
    "                                     )\n",
    "    if self.attention_model:\n",
    "        attention_generator = ImageDataGenerator(preprocessing_function = self.attention_model.heatmap)\n",
    "    else:\n",
    "        attention_generator = None\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(directory=self.train_dir, class_mode='sparse',shuffle=True,\n",
    "                                                  batch_size=self.batch_size,target_size=self.target_size)\n",
    "    validation_generator = test_datagen.flow_from_directory(directory=self.test_dir, class_mode='sparse',shuffle=False,\n",
    "                                                       batch_size=self.batch_size,target_size=self.target_size)\n",
    "    return train_generator, validation_generator, attention_generator\n",
    "  \n",
    "  def create_class_weight(self, labels_dict, mu):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "      score = math.log(mu*total/float(labels_dict[key]))\n",
    "      score = mu*total/float(labels_dict[key])\n",
    "      class_weight[key] = score if score > 1.0 else 1.0\n",
    "    return class_weight\n",
    "\n",
    "  def set_class_weight(self, mu):  \n",
    "    class_dict = dict()\n",
    "    for dir in os.listdir(self.train_dir):\n",
    "      class_dict[dir] = len(os.listdir(f\"{self.train_dir}/{dir}\"))\n",
    "\n",
    "    weights = self.create_class_weight(class_dict, mu)\n",
    "    self.class_weight = {}\n",
    "    class_indices = self.train_generator.class_indices\n",
    "    for cls in weights:\n",
    "      self.class_weight[class_indices[cls]] = weights[cls]\n",
    "  \n",
    "  def _callback(self):\n",
    "    filepath = self.checkpoint_path + '/weights.h5'\n",
    "    checkpoint_dir = os.path.dirname(self.checkpoint_path)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    verbose=2,\n",
    "                                                    save_best_only=True)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "    return [cp_callback,learning_rate_reduction]\n",
    "  \n",
    "  def model_architecture(self, model_params, CLASS_N = 3):\n",
    "    \n",
    "    arch = eval(model_params.arch)\n",
    "    input_shape =  (self.target_size[0],self.target_size[1],3)\n",
    "    pretrained = arch(input_shape = input_shape, include_top=False, weights=model_params.pretrained_weight or None)\n",
    "\n",
    "    for layer in pretrained.layers:\n",
    "      layer.trainable = not(model_params.freeze_pretrained)\n",
    "    \n",
    "    x = Flatten()(pretrained.layers[-1].output)\n",
    "    #x = Dense(5000, kernel_regularizer=regularizers.l1_l2(0.00001), activity_regularizer=regularizers.l2(0.00001), activation='relu',kernel_initializer=tf.keras.initializers.he_normal())(x) \n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(CLASS_N, activation = 'softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = pretrained.input, outputs = x)\n",
    "    print(\"New model created\")\n",
    "    return model\n",
    "  \n",
    "  def load_trained_model(self):\n",
    "    if os.path.exists(self.checkpoint_path):\n",
    "      print(\"Trained model exists and it will be loaded\")\n",
    "      self.model = load_model(f'{self.checkpoint_path}/model.h5')\n",
    "      self.model.load_weights(f'{self.checkpoint_path}/weights.h5')\n",
    "      return True\n",
    "    return False\n",
    "  \n",
    "  def train(self, epochs=10, verbose=2):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "      model_info = self.model.fit(\n",
    "                      x=self.train_generator, \n",
    "                      steps_per_epoch=self.train_generator.samples // self.batch_size+1,  \n",
    "                      epochs=epochs, \n",
    "                      validation_steps=self.validation_generator.samples // self.batch_size+1,\n",
    "                      validation_data=self.validation_generator, \n",
    "                      verbose=verbose,\n",
    "                      callbacks=self._callback(),\n",
    "                      class_weight=self.class_weight\n",
    "                  )\n",
    "      self.model_info = model_info\n",
    "      with open(f'{self.model_dir}/history.json','w') as fp:\n",
    "        json.dump(str(self.model_info.history), fp)\n",
    "    \n",
    "  def confusion_matrix(self):    \n",
    "    Y_pred = self.model.predict(self.validation_generator, self.validation_generator.samples // self.batch_size+1)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    cm = confusion_matrix(self.validation_generator.classes, y_pred)\n",
    "    target_names = list(self.validation_generator.class_indices.keys())\n",
    "    cls_rpt = classification_report(self.validation_generator.classes, y_pred, target_names=target_names)\n",
    "    #self.plot_confusion_matrix(cm, target_names)\n",
    "\n",
    "  def plot_confusion_matrix(self):\n",
    "    \n",
    "    normalize=False\n",
    "    title='Confusion matrix'\n",
    "    cmap=plt.cm.Blues\n",
    "    \n",
    "    Y_pred = self.model.predict(self.validation_generator, self.validation_generator.samples // self.batch_size+1)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    cm = confusion_matrix(self.validation_generator.classes, y_pred)\n",
    "    classes = list(self.validation_generator.class_indices.keys())\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')  \n",
    "    print(set(y_pred))\n",
    "    \n",
    "    cls_rpt = classification_report(self.validation_generator.classes, y_pred, target_names=classes)\n",
    "    print(cls_rpt)\n",
    "\n",
    "  def display_training_curves(training, validation, title, subplot):\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('modelhttp://127.0.0.1:8888/notebooks/notebooks/kiru/framework.ipynb# '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['training', 'validation'])\n",
    "\n",
    "  def show_plot():\n",
    "    plt.subplots(figsize=(10,10))\n",
    "    plt.tight_layout()\n",
    "    display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
    "    display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention model\n",
      "Found 25500 images belonging to 3 classes.\n",
      "Found 1992 images belonging to 3 classes.\n",
      "New model created\n"
     ]
    }
   ],
   "source": [
    "name = 'vgg16'\n",
    "model_config = yaml.safe_load(yaml_config)\n",
    "model_trainer = ModelTrainer.load_from_config(model_config[name],'/home/ubuntu/data/3classes/', retrain = True)\n",
    "model_trainer.class_weight = {0:2.5,1:4,2:1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bcc': 0, 'mel': 1, 'others': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer.validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797/797 [==============================] - 175s 220ms/step - loss: 4.0060 - accuracy: 0.7307 - val_loss: 2.9592 - val_accuracy: 0.6295\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.95919, saving model to /home/ubuntu/data/3classes//models/vgg16-1/weights.h5\n",
      "{0, 1, 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bcc       0.22      0.91      0.35        99\n",
      "         mel       0.28      0.62      0.38       219\n",
      "      others       0.94      0.61      0.74      1674\n",
      "\n",
      "    accuracy                           0.63      1992\n",
      "   macro avg       0.48      0.71      0.49      1992\n",
      "weighted avg       0.83      0.63      0.68      1992\n",
      "\n",
      "797/797 [==============================] - 176s 220ms/step - loss: 3.0593 - accuracy: 0.7591 - val_loss: 2.2053 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.20533, saving model to /home/ubuntu/data/3classes//models/vgg16-1/weights.h5\n",
      "{0, 1, 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bcc       0.25      0.79      0.38        99\n",
      "         mel       0.28      0.60      0.38       219\n",
      "      others       0.94      0.68      0.79      1674\n",
      "\n",
      "    accuracy                           0.67      1992\n",
      "   macro avg       0.49      0.69      0.51      1992\n",
      "weighted avg       0.83      0.67      0.72      1992\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    model_trainer.train(epochs=1,verbose=1)\n",
    "    model_trainer.plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
